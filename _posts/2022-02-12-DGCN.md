---
title: "[Paper] DGCN"
toc: true
use_math: true
---

"DGCN: Diversified Recommendation with Graph Convolutional Networks "이란 논문에 대한 리뷰입니다.

원문은 [링크](https://dl.acm.org/doi/abs/10.1145/3442381.3449835?casa_token=jku3v2po5k0AAAAA:_CP6_w8fhaILXTXoqwEcW-jpt3VMNOR5t-DiayEcK99QF4HfsB67BtCsDiK5WB-SeonpEEsyPwc57AI)에서 확인할 수 있습니다.



# 1. Introduction

**기존의 diversity model의 경우**

- candidates가 생성된 이후에 post=processing 형태로 사용

- Learning To Rank(LTR)기반의 방법들은 candidates를 생성하지 말고 ordered list를 바로 생성해내는 방법을 제안

- 다만 post-processing이라는 점에서 embedding을 학습시키는 mating process와는 분리된 형태

**Graph 관점에선**

- 기존엔 random walk 혹은 GCN과 같은 모델을 사용

- bipartite라는 점에서 한 사용자의 higher order neighbor는 비슷한 사용자가 좋아하는 아이템을 포함한다는 점에서 더 diverse

- GCN의 경우에는 embedding 학습(relevance)와 diversity가 분리된다는 문제를 해결할 수 있습니다.
 - 다만 higher order neighbor가 서로 비슷하지 않은 아이템을 말하진 않습니다.

**해당 페이퍼에선**

- GCN으로 category diversification을 타겟

- Negative samppling을 이용하여 비슷하지만 negative한 아이템을 뽑을 확률을 상승

- 궁극적으로 **다양성을 반영하는 프로세스가 embedding 학습 과정에 반영**되도록 하는 모델을 제안

# 2. Preliminaries

## 2.1 Diversity

*한 사용자의 추천 목록이 서로 얼마나 다양한지* 
~~서로 다른 사용자에게 추천되는 아이템들이 얼마나 다양한지~~

## 2.2 Recommendation Pipeline

기존의 진행 방향은 다음과 같습니다.

Step 1. Matching : user, item 임베딩으로 interaction probability를 기준으로 전체 아이템 목록에서 추천할 후보들을 정합니다. <br>
Step 2. Scoring  : 후보들 중에서 일종의 점수를 매기고 top-k를 선택합니다. <br>
Step 3. Re-ranking : 각각 목적에 따라 top-k를 재배열합니다. <br>

기존의 방식에선 Re-ranking에서 diversity를 반영한 것이라 matching 단계에선 diversity와는 무관했고, 본 논문에선 matching 단계에서 반영되는 방식을 다루는 것입니다.

# 3. Method
## 3.1 Overview

1. [Rebalanced Neighbor Discovering](#33-rebalanced-neighbor-discovering) : 주요 카테고리는 제한적이면서 마이너 카테고리는 올라간 확률로 sampling해서 graph를 구성

2. [Category-Boosted Negative sampling](#34-category-based-negative-sampling) : simliar but negative item이 뽑힐 확률를 올려서 비슷한 아이템들에 대한 사용자의 선호도를 학습

3. Adversarial Learning : 카테고리 분류를 adversarial learning으로 학습시켜서 사용자의 item에 대한 선호도를 이용해  **카테고리에 대한 선호도**를 알아내어 category에 대한 데이터 없이 임베딩을 학습


## 3.2 GCN
### 3.2.1 임베딩 환경
M : the number of users

N : the number of items

d : the dimension of embedding

### 3.2.2 Convolutional Layer
$kth$ layer의 node $v$의 계산과정은 다음과 같습니다.

> $h^{k}_{AGG} = MEAN(h_{j}^{k-1}, \forall j \in \mathcal{N}(v))$ 
> $h_{v}^{k} = \tanh (W^{k}h^{k}_{AGG}$
 - $\mathcal{N}(v))$ 는 sampled neighbor set이며 self node도 포함되어 있습니다.

### 3.2.3 Interaction Modeling in matching stage

gonvolutional layer의 마지막 representation의 내적으로 interaction probability를 계산합니다.

> $\mathcal{p}_{u,i}$ = <$h_{u}^{K}, h_{i}^{K}$>

## 3.3 Rebalanced Neighbor Discovering
item 수가 매우 크기 때문에 neighbor sampler가 사용하는데 이 neighbor sampler는 일종의 *Node Flow*처럼 작동합니다.

이는 첫 layer에선 ranodm하게 neighbor를 샘플링하고 다음 레이어에서는 직전 레이어를 바탕으로 neighbor를 샘플링하게 됩니다.

즉 하나의 convolutional layer에서는 하나의 sub graph(block)을 연사에 사용하게 됩니다. 

<!-- (사진) -->

diversity를 다루기 위해 한 사용자에 대해선 자주 보는 카테고리(dominant)와 그렇지 않은 카테고리(disadvantaged)는 구분해서 dominant와 disadvantaged 카테고리 모두 추천할 수 있어야 합니다.

그래서 해당 논문에선 **disadvantaged 카테고리를 샘플링할 확률을 올려주고 dominant는 줄여주는 것**입니다.

bipartite graph이니 
- 한 사용자 node에 대해선 연결된 카테고리의 히스토그램을 그리고 여기에 반대되는 값(inverse)을 샘플링 확률로 사용하고 이를 rebalance weight $\alpha$라고 부릅니다.
- 한 아이템 node에 대해선 연결된 사용자를 uniform sampling으로 진행합니다.

이렇게 진행하면 사용자 임베딩에 보다 다양한 카테고리 정보가 반영되고, 추천할 때엔 이렇게 학습된 사용자 임베딩으로 최종 추천 목록을 만들게 됩니다.

한 레이어의 block을 구성하는 알고리즘은 다음과 같습니다.
1. 각 node마다 샘플링 확률을 구합니다.
    - 사용자 node는 히스토그램의 inverse를, 아이템 node는 uniform 분포값을 가져옵니다.
2. 샘플링 확률로 뽑은 샘플을 모든 node에 대해 반복합니다.

<!-- 이렇게 하면 좀 이상할 것 같은데 -->

## 3.4 Category-based Negative Sampling

implicit feedback을 사용할 경우 positive sample은 다루지만 negative sample은 기록이 없는 아이템에서 생각해야한다는 단점이 있습니다.

그래서 negative sample을 postive sample마다 적절한 수만큼 뽑아서 사용자 임베딩은 positive sample과는 비슷해지게, negative sample과는 달라지게 학습합니다.

해당 논문에서는 *similar but negative* 아이템을 서용한다고 합니다.

**simlar but negative란**
같은 카테고리 내 positive sample을 말합니다.

즉 **positive category에서 negative sample**을 뽑아서 같은 카테고리이지만 negative sample은 최종 추천단계에서 덜 뽑히게 되어 다양하게 만드는 방식입니다.

알고리즘은 다음과 같습니다.
1. 각 positive sample $i$를 준비합니다.
2. $i$를 전체 아이템 집합에서 제외된 집합 N과 같은 카테고리 아이템 집합에서 제외된 집합 S를 준비합니다.
3. $\beta$에 따라 S나 N 중에서 하나를 선택하여 negative sample로 사용합니다.
 - $\beta$는 사전에 정한 *simliar but negative* 비율을 말합니다. 
4. 최종적으로 모든 positive sample과 샘플링으로 뽑은 negative sample을 최종 training에 사용하는 데이터 셋이 됩니다.

$\beta$값이 증가할수록 positive category에 속하지만 negative하다고 정해진 item이 늘어나 결과적으로 negative 카테고리 중 positive 아이템이 추천될 확률이 증가하는 방식으로 작동하게 됩니다.

전체 training sample의 구성
|:---:|:---:|:---:|
|$\beta \uparrow$ |positive(dominant) category| negative(disadvantaged) category|
|positive item|고정(positive sample)| 감소|
|negative item|증가(negative sample)| 감소|

전체 뽑힐 확률
|:---:|:---:|:---:|
|$\beta \uparrow$ |positive(dominant) category| negative(disadvantaged) category|
|positive item|$\dot$| 증가|
|negative item|감소|$\dot$|






