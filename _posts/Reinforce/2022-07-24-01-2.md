---
title: "[KMOOC 강화학습] Week 01-2 Multi-armed Bandit 문제"
toc: true
use_math: true
categories:
  - Reinforcement Learning
tags:
  - [KMOOC]
---

해당 강의는 K-MOOC의 "강화학습의 수학적 기초와 알고리즘 이해" 수업을 수강하며 기록한 내용입니다. 강의는 [링크](http://www.kmooc.kr/courses/course-v1:KoreaUnivK+ku_ai_002+2020_A44/course/)에서 확인하실 수 있습니다.


# Multi-armded bandit 문제란

- 환경 : 여러 슬롯 머신이 있고 각 bandit machine에 대한 상태(State)정보는 부재
- 행동 : 하나를 선택하여 당김.
- 보상 : 동일한 돈이 나오지 않고 슬롯마다 금액이 다른 보상.

## 해결책(일반적인 강화학습 방법)

1. Exploration : 아무것도 모르는 상태에서 랜덤하게 탐색 시작
2. Exploitation : 누적된 시도의 보상을 보고 의사 결정

## 행동과 목적

주어진 횟수에서 총 보상을 최대화하는 슬롯 머신을 선택


## 의사 예시

- 학습 주체(agent) : 의사
- 환경 : 어떤 약이 좋은 지 모름
- 행동 : 임상시험 중에 약 처방
- 보상 : 복용 후 증상으로 좋고 나쁜 점 확인

🌟 결론

- 학습 주체(agent)가 k개의 행동(action) 중 하나를 선택
- 선택한 행동에 보상(rewar)을 받는 일련의 과정 수행
- **일정 기간동안 취득한 보상의 총합**에 대한 기대값을 최대화하도록 어떤 행동을 취할지 결정


# 행동 가치(action value)

어떠한 행동을 취했을 때 보상에 대한 기댓값

$ q(a) = E[R_t | A_t = a] = \sum_r p(r|a) r$


⚡ 다만 학습주체가 행동가치에 대한 분포를 모른다! 

**이것을 모르기에** k-armed bandit의 challenge가 되며 행동 가치 함수를 **try & error로 추정**할 수 있게 된다면 좋은 action을 취할 수 있게 된다.

## 추정 방법

1. 표본 평균 방법(Sample-mean method) : 전체 보상 합 / 선택한 횟수
  - $Q_{n+1} = {1\over n} \sum_{i=1}^{n} R_{i} = Q_{n} + {1\over n}(R_{n} - Q_{n}) $
2. 

