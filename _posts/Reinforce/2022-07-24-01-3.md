---
title: "[KMOOC 강화학습] Week 01-2 강화학습 맛보기"
toc: true
use_math: true
categories:
  - Reinforcement Learning
tags:
  - [KMOOC]
---

해당 강의는 K-MOOC의 "강화학습의 수학적 기초와 알고리즘 이해" 수업을 수강하며 기록한 내용입니다. 강의는 [링크](http://www.kmooc.kr/courses/course-v1:KoreaUnivK+ku_ai_002+2020_A44/course/)에서 확인하실 수 있습니다.

# Q 러닝

$Q(s_{t},a_{t}) \gets (1-\alpha)Q(s_{t},a_{t}) + \alpha(r_{t+1}_\gamma \max_{a} Q(s_{t+1},a))$

- 기존까지의 추정치에 새로 얻어진 정보로 업데이트
- Bandit과 방식은 유사하다.
- 다만 **대상**은?

## 디티일 

어떤 경로에 따라 최대의 누적 보상을 얻는지 학습하며 방향성을 제시하는 것이 바로 $Q$에 해당한다.

- 환경 : 그리드에 대한 정보는 없다.
- State : 로봇의 현재의 위치(1,2,3,4,5,6)
- Action : 움직이는 방향(화살표)

Q는 **누적 보상의 최대값에 대한 추정치**로 정의된다.

